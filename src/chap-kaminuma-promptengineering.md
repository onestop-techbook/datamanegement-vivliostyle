---
class: chapter
---

# AIからの応答データを操る！プロンプトエンジニアリングの実装記録



最近、Gemini APIを使ったWebアプリケーションを個人的に作る機会があり、その過程でプロンプトエンジニアリングの複数の技術を組み合わせる実装に取り組みました。

その時の実装内容をサンプルとして下記のGithubページに置いているので
そちらのコードも確認しながら読んでもらえたらと思います。

**「　サンプルのURL　」**

本記事では、プロンプトエンジニアリングとは？というところから、実装した内容を解説するような進め方をしていきます。

一人で試行錯誤しながら作ったものなので改善点も多いと思いますが、実装過程で気づいたことや躓いた点の記録としても読んでもらえたらなと思います。

同じような課題に取り組まれる方の参考になれば幸いです。



## プロンプトエンジニアリングとは

**プロンプトエンジニアリング**とは、AI（特に大規模言語モデル）に対して適切な指示を与えることで、期待する品質の回答を安定して得るための技術です。

単純に「質問を投げる」だけではなく、**AIの特性を理解した上で戦略的に指示を設計する**分野として注目されています。


## なぜ必要なのか？

例えば、同じ「売上データを分析して」という依頼でも、プロンプトの書き方次第で結果は大きく変わります。

* 毎回違う形式で回答が返ってくる
* 重要な観点が抜け落ちる
* 期待とは異なる分析をしてしまう


そういった状況を打破するために、プロンプトエンジニアリングの手法を用いることができます。

### プロンプトエンジニアリングの役割

プロンプトエンジニアリングは、こうした問題を解決し、**AIを実用的なシステムの一部として活用するための必須技術**となってきています。

つまり「AIにうまく話しかける」ためのテクニックではなく、
**システム設計の一部としてどうプロンプトを組み込むか**を考えることこそが本質だとも言えます。
最近ではAI駆動開発や、VibeCodingなどでもプロンプトの意識は必須となってきていると思います。

---

## 最初の問題意識：単発プロンプトの限界

最初は単純に「ユーザーの活動データをAIに投げて分析してもらおう」という発想でした。しかし実際にやってみると、毎回出力がバラバラだったり、時には的外れな回答が返ってきたりしました。

単純なプロンプトだと、AIは確かに何かしら答えてくれるのですが、品質が安定しません。
システム上求める観点とずれていたり、毎回違う形式で返ってきたりします。
これでは実用的なシステムにはなりません。

そこで、プロンプトエンジニアリングの技術を組み合わせて、もう少し安定した品質のシステムにできないかと考え始めました。

## アーキテクチャ設計：責任分離の重要性

まず実施したのは、プロンプト生成の部分を独立したクラスにすることでした。

API呼び出しの処理と混ぜこぜにしてしまうと、後でプロンプトだけを調整したい時に大変になってしまうため、独立したクラスにすることで視認性と実用性があがると考えています。

今回用意したサンプルには、実際に `GeminiPromptBuilder` という専用クラスを作って、
5つのプロンプト技術を順次適用してから最終的なプロンプトを生成するようにしました。

```python
class GeminiPromptBuilder:
    """
    Gemini API用のプロンプトを生成するクラス
    一般的なプロンプトエンジニアリング技術を活用
    """
    
    def build_prompt(self, activities: List[Activity], daily_moods: List[DailyMood], request: AnalysisRequest) -> str:
        prompt_parts = [self.SYSTEM_ROLE]
        
        # データコンテキストの提供（Few-shot Prompting）
        prompt_parts.append(self._format_activity_data(activities))
        prompt_parts.append(self._format_daily_mood_data(daily_moods))
        
        # 分析焦点の指示（Task-specific Prompting）
        prompt_parts.append(self.FOCUS_INSTRUCTIONS[request.analysis_focus])
        
        # 詳細レベルと応答スタイルの指定
        prompt_parts.append(self.DETAIL_INSTRUCTIONS[request.detail_level])
        prompt_parts.append(self.STYLE_INSTRUCTIONS[request.response_style])
        
        return "\n".join(prompt_parts)
```

この設計にしたことで、プロンプト生成のロジックを独立してテストすることなどもできるようになります。
後で「あれ、この部分の出力がおかしいな」と思った時に、プロンプトだけを単体で確認して調整することもできて、とても便利がいいので構成としておすすめです。

## プロンプト設計の5つの要素と実装

### System Message：AIの役割と専門性を定義する技術

**System Messageとは何か？**

System Messageは、AIに対して「どのような役割や専門性を持って応答してほしいか」を明確に伝える技術です。

人間に例えると、「あなたは医師として」「あなたは教師として」といった役割設定をするようなものです。

**どのような場面で効果的か？**

- 専門的な知識が必要な分野での回答を求める場合
- 特定の観点や立場からの分析が欲しい場合
- 回答のトーンや方向性を統一したい場合
- 一貫性のあるアドバイスが必要な場合
- 語尾や口調を指示して変えたい時などにも効果的

**期待できる利点**

- 回答の品質と一貫性が大幅に向上します
- 専門外の内容に逸脱することを防げます
- ユーザーの期待に沿った回答を得やすくなります
- 信頼性の高い情報提供が可能になります

**実装での学び**

最初は「あなたは専門家です」程度の短いメッセージにしていましたが、それだと以下のような問題が頻発しました。

* データを見ずに一般論だけを述べる回答

  例：「運動不足のようですね。バランスの良い食事と適度な運動を心がけましょう」

* 活動データの中身を詳しく分析しない

  → 表面的な印象だけでコメントしてしまう

* 毎回異なる観点で分析する

  → 継続的な改善につながらない

---

そこで、具体的に **「データに基づいた洞察」** や **「建設的なアドバイス」** を求めることを明記したところ、格段に回答が安定しました。

```python
SYSTEM_ROLE = """あなたは健康とウェルネスの専門家です。
ユーザーの生活パターンを分析し、データに基づいた洞察と建設的なアドバイスを提供します。
以下のデータを詳しく分析して、ユーザーの生活の質向上に役立つフィードバックをお願いします。"""
```

重要だと感じたのは、単に役割を伝えるだけでなく、「どのような観点を重視してほしいか」「どのような情報を避けてほしいか」まで明確に指示することです。

### Few-shot Prompting：実例を示して学習を促進する技術

**Few-shot Promptingとは何か？**

Few-shot Promptingは、AIに対して「このような入力に対してはこのような出力をしてほしい」という具体例を提示することで、望ましい回答パターンを学習させる技術です。言葉での説明よりも、実例を見せる方が理解が深まるという考え方に基づいています。

**どのような場面で効果的か？**

- 特定の出力形式を守ってほしい場合
- 複雑なデータを特定の方法で解釈してほしい場合
- 抽象的な指示だけでは期待通りの結果が得られない場合
- データ分析の観点や着眼点を示したい場合

**期待できる利点**

- AIが求められている処理を正確に理解できます
- 出力の品質と一貫性が大幅に向上します
- 複雑な処理でも例を通じて直感的に伝えることができます
- 学習効果により、類似のケースでも適切な処理が期待できます

**実装での学び**

今回の実装では、生の活動データをAIが理解しやすい構造化された形式に変換して提示しました。最初はJSON形式で渡していましたが、AIがうまく理解してくれないことが多くありました。

そこで、人間が見ても分かりやすい時系列の視覚的な形式に変更したところ、AIの理解度が格段に向上しました。

```python
def _format_activity_data(self, activities: List[Activity]) -> str:
    formatted_lines = ["【活動データ（時系列順）】"]
    
    # 日付でグループ化
    activities_by_date = {}
    for activity in activities:
        date_str = activity.date.strftime('%Y-%m-%d (%A)')
        if date_str not in activities_by_date:
            activities_by_date[date_str] = []
        activities_by_date[date_str].append(activity)
    
    # 各日の活動を視覚的に整形
    for date_str, daily_activities in sorted(activities_by_date.items()):
        formatted_lines.append(f"\n◆ {date_str}")
        for activity in daily_activities:
            time_range = activity.get_time_range_str()
            activity_line = f"  {time_range} - {activity.title}"
            if activity.category:
                activity_line += f" [{activity.category}]"
            formatted_lines.append(activity_line)
```

この経験から、「AIが理解しやすい形式」は必ずしも機械的な形式ではなく、むしろ人間にとって直感的な形式の方が効果的である場合もあることを学びました。
これは、LLMが大量の自然言語テキストを学習しており、人間に読みやすい文章や箇条書きの形式の方が、文脈や意図をより正確に理解しやすいためであることも起因しているようです。


また、データの提示方法も重要な要素でした。単にデータを渡すだけでなく、事前に統計情報（平均値、分布、トレンド等）を計算して一緒に提示することで、AIの分析精度が大幅に向上しました。

### 出力制御：一貫した形式での回答生成

**出力制御とは何か？**

出力制御は、AIの出力を特定のテンプレートや形式に従わせる技術です。「このような構造で回答してください」という明確な指示を与えることで、一貫した形式の出力を得ることができます。レポートや文書作成でテンプレートを使うのと同じ考え方です。

**どのような場面で効果的か？**

- 報告書や分析結果など、決まった形式で出力したい場合
- 複数の観点を漏れなく含めた分析が欲しい場合  
- 後処理しやすい構造化された出力が必要な場合
- ユーザーが慣れ親しんだ形式で情報を受け取りたい場合

**期待できる利点**

- 出力形式が統一され、処理しやすくなります
- 必要な情報が漏れることを防げます
- ユーザーにとって読みやすく理解しやすい形式にできます
- システムとしての完成度と信頼性が向上します

**実装での学び**

分析の詳細度（簡潔版、標準版、詳細版）に応じて、異なるテンプレートを適用するようにしました。最初は詳細度に関係なく同じ形式で出力していましたが、ユーザーによっては「もっと詳しく知りたい」「要点だけ知りたい」という異なるニーズがあるだろうと思い実装しました。

テンプレート設計で重要だと感じたのは、「情報の階層化」です。

最も重要な情報を最初に配置し、詳細情報は後に配置することで、どの詳細度でも読みやすい出力になりました。

### 動的調整：ユーザー設定に応じた分析切り替え

**動的調整とは何か？**

動的調整は、同じ基本的な処理でも、パラメータを変更することで出力の内容や形式を動的に調整する技術です。一つのシステムで、ユーザーの好みや状況に応じてAIの動作を柔軟に変更できます。

**どのような場面で効果的か？**

- ユーザーの好みや専門レベルが様々な場合
- 同じデータでも異なる観点からの分析が必要な場合
- システムを様々な用途や文脈に対応させたい場合
- カスタマイズ性を重視したい場合

**期待できる利点**

- 一つのシステムで多様なニーズに対応できます
- ユーザーが自分に合った出力を選択できます
- システムの柔軟性と再利用性が大幅に向上します
- 開発効率が向上し、メンテナンスも容易になります

**実装での学び**

分析の焦点（ムード（気分）重視、活動重視、バランス重視、ウェルネス重視）を動的に切り替える仕組みを実装しました。最初は「総合的な分析」を一つだけ提供していましたが、生活の振り返りという機能を利用するユーザーの関心ポイントは異なる視点で分析できた方がいいのではないかと考えて今回の実装に組み込みました。

パラメータ化する際の重要なポイントは、「意味のある組み合わせ」を提供することです。

無制限にカスタマイズできるよりも、実装側でしっかりと考えられた選択肢を提供してユーザーは選ぶだけで分析可能とした方が、結果的にユーザーの満足度は高くなるのではと現状思っています。

### スタイル調整：トーンと語り口の制御

**スタイル調整とは何か？**

スタイル調整は、同じ内容でも異なるトーン（専門的、親しみやすい、励まし重視など）で表現させる技術です。内容は同じでも、伝え方によって受け手の印象や理解度が大きく変わることを活用した技術です。

**どのような場面で効果的か？**

- ユーザーの性格や好みが様々な場合
- 同じ情報でも受け取り方を最適化したい場合
- モチベーション向上や親しみやすさを重視したい場合
- 専門レベルの異なるユーザーに対応したい場合

**期待できる利点**

- ユーザーのモチベーションや満足度を大幅に向上させられます
- 同じシステムでも個人に合わせたパーソナライゼーションが可能です
- 情報の受容度と理解度が向上します
- ユーザーエンゲージメントの向上が期待できます

**実装での学び**

親しみやすい、専門的、励まし重視、カジュアルという4つのスタイルを実装しました。実際に作ってみて驚いたのは、同じデータでも伝え方次第で受け取る側の印象が劇的に変わることです。

例えば「睡眠時間が不足している」という事実を伝える場合でも、専門的スタイルでは「データによると平均睡眠時間が推奨値を下回っています」となり、親しみやすいスタイルでは「睡眠時間がちょっと短めかもしれませんね」という風になります。

重要だと感じたのは、スタイルを変えても「事実の正確性」は保持することです。伝え方を変えても、根本的な情報の質を落としてはいけません。

## 統合実装での重要な学び

### データ前処理の戦略的重要性

AIに生データをそのまま渡すのではなく、事前に統計情報を計算して構造化することにしました。

これにより二つの大きなメリットがありました。

1. **AIの計算ミスを防ぐ**: AIに計算を任せると、時々微妙に間違った数値を使うことがありました（これは一般的に利用されてるOpenAIやGeminiなどでも起きることです）
2. **一貫した分析基準**: 事前に計算することで、毎回同じ基準で分析できるようになりました

この改善により、分析結果の信頼性が格段に向上しました。

### エラーハンドリングの現実的重要性

作っていて実装が終わった時点では「APIはきちんとレスポンスを返す」ことを前提に設計していると思いますし、そう思い込んでしまいがちです。
しかし実際に運用を始めると、AIのAPI実装でもあっけなく崩れ去ったりもします。
私が遭遇したのは次のようなエラーです。（本サンプルの実装以外のものも含む）

- レート制限エラー（1分間のリクエスト数オーバー）
- トークン数制限エラー（プロンプトが長すぎる）
- ネットワークタイムアウト
- 一時的なサービス障害

これらに対処するため、エラーの種類を判別して適切な対処を行う仕組みを実装しました。`_call_gemini_api`メソッドは`GeminiAnalysisService`クラス内に配置し、以下のようなリトライ機能を実装しました。

```python
def _call_gemini_api(self, prompt: str, max_retries: int = 3) -> Any:
    """リトライ機能付きのAPI呼び出し"""
    for attempt in range(max_retries):
        try:
            response = self.model.generate_content(prompt, generation_config=self.generation_config)
            return response
        except Exception as e:
            error_message = str(e).lower()
            
            # リトライする価値があるエラーかを判定
            if attempt < max_retries - 1:
                if any(keyword in error_message for keyword in 
                      ['rate limit', 'quota', 'timeout', 'network']):
                    wait_time = (2 ** attempt) + 1  # 指数バックオフ
                    time.sleep(wait_time)
                    continue
            break
    
    raise RuntimeError(f"API呼び出しが失敗しました: {str(e)}")
```

特に「リトライする価値があるエラー」と「即座に諦めるべきエラー」を区別することはアプリ実装の上ときに外部APIとの連携時には実装を検討してもいいかもしれません。

また、エラーメッセージをユーザーにとって分かりやすい言葉に変換することも重要だと改めて感じました。

技術的なエラーコードではなく、「何が起こったか」「どうすれば良いか」を伝えることが大切ですね。

### プロンプト長の最適化

最初の頃は「詳しい指示を出せばより良い回答が得られる」と思って、プロンプトをどんどん長くしていました。しかし実際には、長すぎるプロンプトには以下の問題がありました。

- トークン数制限に引っかかる
- AIが重要な部分を見失う
- レスポンス時間が長くなる
- コストが増加する

対策として、プロンプトの「核心部分」と「補助部分」を明確に分けて、状況に応じて省略できるようにしました。

結果的に、短くても的確なプロンプトの方が良い結果を得られることが多いと分かりました。

## 実運用における課題と対策

### 期待と異なる回答への対処

どんなに詳細にプロンプトを書いても、時々期待と違う回答が返ってくることがあります
。これは完全に防ぐことはできませんが、以下の対策で大幅に改善できました。

1. **出力形式をより具体的に指定する**: 抽象的な指示ではなく、具体例を示す
2. **望ましくない回答例も示す**: 「このような回答はしないでください」という指示も有効
3. **重要な制約は繰り返し強調する**: 一箇所だけでなく、複数箇所で同じ制約を伝える

### データ不足時の適切な対応

活動データやムードデータが少ない（1-2日分しかない）場合、AIが適切な分析をするのが困難になります。
この場合は、分析を実行する前段階でデータ量をチェックし、不十分な場合は専用のメッセージを返すようにしました。

「分析できませんでした」ではなく、「なぜ分析が困難なのか」「どれくらいのデータがあれば良いか」を具体的に伝えることで、ユーザーの理解と満足度が向上しました。

## 今後への展望

この実装を通じて、プロンプトエンジニアリングは単なる「文章作成のテクニック」ではなく、
「システム設計の重要な要素」であることを実感しました。

特に複数の技術を組み合わせることで、単一技術では不可能な柔軟性と品質を実現できることが分かりました。ただし、技術の組み合わせには相互作用があるため、全体のバランスを考慮した設計が重要です。

今後は、さらに多くの実用例を通じて、これらの技術の効果的な活用方法を深めていきたいと思います。

## おわりに

個人的なプロジェクトにAIによる振り返りの仕組みを入れたいなと言ったところから学習をはじめたものでしたが、プロンプトエンジニアリングの奥深さと実用性の高さを改めて実感しました。

ベストプラクティスな実装ではありませんが、これらの経験が同じような課題に取り組まれる方の参考になれば幸いです。プロンプトエンジニアリングは急速に発展している分野ですので、今後の参考になれば幸いです。

長文にお付き合いいただき、ありがとうございました。